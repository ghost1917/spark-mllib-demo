{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "spark_home='/opt/spark-1.5.1-bin-hadoop2.6/'\n",
    "# addin pyspark to current path\n",
    "sys.path.append( spark_home+'/python' )\n",
    "sys.path.append( spark_home+'/python/lib/py4j-0.8.2.1-src.zip' )\n",
    "\n",
    "# Установка локальных переменных\n",
    "os.environ[\"SPARK_HOME\"] = spark_home\n",
    "os.environ[\"HADOOP_HOME\"] = '/opt/cloudera/parcels/CDH/lib/hadoop'\n",
    "os.environ[\"HADOOP_YARN_HOME\"] = '/opt/cloudera/parcels/CDH/lib/hadoop-yarn'\n",
    "os.environ[\"YARN_CONF_DIR\"] = '/etc/hadoop/conf.cloudera.yarn'\n",
    "os.environ[\"SPARK_CLASSPATH\"] = '/etc/hive/conf.cloudera.hive1'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = '--master local[4] pyspark-shell'\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import HiveContext\n",
    "conf = SparkConf ().set( 'spark.app.name', 'test');\n",
    "sc = SparkContext (conf= conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка датасета, с которым мы проводим эсперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# загружаем датасет\n",
    "from pyspark.mllib.util import MLUtils\n",
    "examples = MLUtils.loadLibSVMFile(sc, \"/testdata/mllib_demo/libsvm_dataset\")\n",
    "\n",
    "\n",
    "# извлекаем фичи из датасета\n",
    "features = examples.map (lambda x: x.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод визуализации ROC кривой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotROC (real_labels, predicted_labels):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, _ = roc_curve(real_labels, predicted_labels)\n",
    "    roc_auc = auc (fpr, tpr)\n",
    "\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.clf()\n",
    "    plt.plot(fpr,tpr)\n",
    "    print \"ROC AUC =\", roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><br><br><br>Кластеризация K средних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели KMeans.train с параметрами\n",
    "- **dataset** - датасет векторов\n",
    "- **k** - число кластеров\n",
    "- **maxIterations** - число итераций сходимости\n",
    "- **initializationMode** - дотупные варианты \"k-means||\" (по умолчанию), \"random\"\n",
    "- **runs** - (по умолчанию 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import KMeans\n",
    "\n",
    "# Build the model (cluster the data)\n",
    "clusters = KMeans.train(features, 2, maxIterations=10,\n",
    "        runs=10, initializationMode=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotROC (examples.map (lambda x: x.label).collect(),\n",
    "         examples.map (lambda x: 1-clusters.predict (x.features)).collect())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
